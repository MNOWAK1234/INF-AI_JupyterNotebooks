{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systemy uczące się - Zad. dom. 1: Minimalizacja ryzyka empirycznego\n",
    "\n",
    "Celem zadania jest zaimplementowanie własnego drzewa decyzyjnego wykorzystującego idee minimalizacji ryzyka empirycznego.\n",
    "\n",
    "### Autor rozwiązania\n",
    "\n",
    "Uzupełnij poniższe informacje umieszczając swoje imię i nazwisko oraz numer indeksu:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NAME = \"Mikołaj Nowak\"\n",
    "ID = \"151813\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twoja implementacja\n",
    "\n",
    "Twoim celem jest uzupełnić poniższą klasę `TreeNode` tak by po wywołaniu `TreeNode.fit` tworzone było drzewo decyzyjne minimalizujące ryzyko empiryczne. Drzewo powinno wspierać problem klasyfikacji wieloklasowej (jak w przykładzie poniżej). Zaimplementowany algorytm nie musi (ale może) być analogiczny do zaprezentowanego na zajęciach algorytmu dla klasyfikacji. Wszelkie przejawy inwencji twórczej wskazane. **Pozostaw komenatrze w kodzie, które wyjaśniają Twoje rozwiązanie.**\n",
    "\n",
    "Schemat oceniania:\n",
    "\n",
    "- wynik na zbiorze Iris (automatyczna ewaluacja) celność klasyfikacji >= prostego baseline'u + 10%: +40%,\n",
    "- wynik na ukrytym zbiorze testowym 1 (automatyczna ewaluacja) celność klasyfikacji >= prostego baseline'u + 15%: +30%,\n",
    "- wynik na ukrytym zbiorze testowym 2 (automatyczna ewaluacja) celność klasyfikacji >= prostego baseline'u + 5%: +30%.\n",
    "\n",
    "Niedozwolone jest korzystanie z zewnętrznych bibliotek do tworzenia drzewa decyzyjnego (np. scikit-learn).\n",
    "Możesz jedynie korzystać z biblioteki numpy.\n",
    "\n",
    "#### Uwaga: Możesz dowolnie modyfikować elementy tego notebooka (wstawiać komórki i zmieniać kod), o ile będzie się w nim na koniec znajdowała kompletna implementacja klasy `TreeNode` w jednej komórce.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class TreeNode:\n",
    "\tdef __init__(self):\n",
    "\t\tself.left: TreeNode | None = None  # Wierzchołek znajdujący się po lewej stronie\n",
    "\t\tself.right: TreeNode | None = None  # Wierzchołek znajdujący się po prawej stronie\n",
    "\t\tself.feature: int | None = None  # Indeks cechy, według której dokonano podziału\n",
    "\t\tself.threshold: float | None = None  # Wartość progowa podziału\n",
    "\t\tself.answer: int | None = None  # Klasa, jeśli wierzchołek jest liściem\n",
    "\n",
    "\tdef fit(self, data: np.ndarray, target: np.ndarray) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tdata (np.ndarray): macierz cech o wymiarach (n, m), gdzie n to liczba przykładów, a m to liczba cech\n",
    "\t\t\ttarget (np.ndarray): wektor klas o długości n, gdzie n to liczba przykładów\n",
    "\t\t\"\"\"\n",
    "\t\t# Nie powinno się wydarzyć, ale lepiej zabezpieczyć\n",
    "\t\tif len(target) == 0:\n",
    "\t\t\tself.answer = 0\n",
    "\t\t\treturn\n",
    "\t\tbestCut = [0.0, None, None] # zysk, cecha, threshold\n",
    "\t\ttarget_counts = Counter(target)  # Tworzy słownik {wartość: liczba_wystąpień}\n",
    "\t\tmost_common_element, count = Counter(target).most_common(1)[0]\n",
    "\t\taccuracy = count/len(target)\n",
    "\t\t# Unikaj overfittingu poprzez niedzielenie małych zbiorów\n",
    "\t\t# Tak samo jeśli dokładność początkowa jest wystarczająco duża to nie dziel już więcej\n",
    "\t\tif(len(data) < 3 or accuracy > 0.9):\n",
    "\t\t\tself.answer = most_common_element\n",
    "\t\t\treturn\n",
    "\t\tnum_features = data.shape[1]  # Liczba cech (kolumn)\n",
    "\t\tfor feature in range(num_features):\n",
    "\t\t\tsorted_indices = data[:, feature].argsort()  # Indeksy sortowania dla danej cechy\n",
    "\t\t\tsorted_data = data[sorted_indices]  # Posortowane wiersze macierzy cech\n",
    "\t\t\tsorted_target = target[sorted_indices]  # Odpowiadający im posortowany wektor klas\n",
    "\t\t\tfor i in range(len(sorted_target) - 1):\n",
    "\t\t\t\tif sorted_target[i] != sorted_target[i + 1]:  # Znaleziono potencjalny próg podziału\n",
    "\t\t\t\t\tthreshold = (sorted_data[i, feature] + sorted_data[i + 1, feature]) / 2\n",
    "                    # Tworzenie podzbiorów\n",
    "\t\t\t\t\tmask_left = data[:, feature] < threshold\n",
    "\t\t\t\t\tmask_right = data[:, feature] >= threshold\n",
    "\t\t\t\t\tdata_left = data[mask_left]\n",
    "\t\t\t\t\tdata_right = data[mask_right]\n",
    "\t\t\t\t\ttarget_left = target[mask_left]\n",
    "\t\t\t\t\ttarget_right = target[mask_right]\n",
    "\t\t\t\t\tdivided_counts_left = Counter(target_left)\n",
    "\t\t\t\t\tdivided_counts_right = Counter(target_right)\n",
    "\t\t\t\t\t# 1 podział: Wszystko po lewo to jedna klasa\n",
    "\t\t\t\t\t# Policz accuracy początkowe bez podziału\n",
    "\t\t\t\t\tinitial_accuracy = target_counts[sorted_target[i]] / len(data)\n",
    "\t\t\t\t\t# Policz accuracy po podziale\n",
    "\t\t\t\t\tcardinality_left = (len(data_left)/len(data))\n",
    "\t\t\t\t\taccuracy_left = (divided_counts_left[sorted_target[i]] / len(data_left)) if len(data_left) > 0 else 0\n",
    "\t\t\t\t\tcardinality_right = (len(data_right)/len(data))\n",
    "\t\t\t\t\taccuracy_right = 1 - (divided_counts_right[sorted_target[i]] / len(data_right)) if len(data_right) > 0 else 1\n",
    "\t\t\t\t\tnew_accuracy = cardinality_left*accuracy_left + cardinality_right*accuracy_right\n",
    "\t\t\t\t\tif(new_accuracy - initial_accuracy > bestCut[0]):\n",
    "\t\t\t\t\t\tbestCut = [new_accuracy - initial_accuracy, feature, threshold]\n",
    "\t\t\t\t\t# 2 podział: Wszystko po prawo to jedna klasa\n",
    "\t\t\t\t\t# Policz accuracy początkowe bez podziału\n",
    "\t\t\t\t\tinitial_accuracy = target_counts[sorted_target[i+1]] / len(data)\n",
    "\t\t\t\t\t# Policz accuracy po podziale\n",
    "\t\t\t\t\tcardinality_left = (len(data_left)/len(data))\n",
    "\t\t\t\t\taccuracy_left = 1 - (divided_counts_left[sorted_target[i+1]] / len(data_left)) if len(data_left) > 0 else 1\n",
    "\t\t\t\t\tcardinality_right = (len(data_right)/len(data))\n",
    "\t\t\t\t\taccuracy_right = (divided_counts_right[sorted_target[i+1]] / len(data_right)) if len(data_right) > 0 else 0\n",
    "\t\t\t\t\tnew_accuracy = cardinality_left*accuracy_left + cardinality_right*accuracy_right\n",
    "\t\t\t\t\tif(new_accuracy - initial_accuracy > bestCut[0]):\n",
    "\t\t\t\t\t\tbestCut = [new_accuracy - initial_accuracy, feature, threshold]\n",
    "\t\tif(bestCut[0] > 0.0):\n",
    "\t\t\tself.left = TreeNode()\n",
    "\t\t\tself.right = TreeNode()\n",
    "\t\t\tself.feature = bestCut[1]\n",
    "\t\t\tself.threshold = bestCut[2]\n",
    "\t\t\tfeature = bestCut[1]\n",
    "\t\t\tthreshold = bestCut[2]\n",
    "\t\t\tmask_left = data[:, feature] < threshold\n",
    "\t\t\tmask_right = data[:, feature] >= threshold\n",
    "\t\t\tdata_left = data[mask_left]\n",
    "\t\t\tdata_right = data[mask_right]\n",
    "\t\t\ttarget_left = target[mask_left]\n",
    "\t\t\ttarget_right = target[mask_right]\n",
    "\t\t\tself.left.fit(data_left, target_left)\n",
    "\t\t\tself.right.fit(data_right, target_right)\t\n",
    "\t\telse:\n",
    "\t\t\tself.answer = most_common_element\n",
    "\t\n",
    "\tdef predict(self, data: np.ndarray) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "    \tArgs:\n",
    "        \tdata (np.ndarray): macierz cech o wymiarach (n, m), gdzie n to liczba przykładów, a m to liczba cech\n",
    "    \tReturns:\n",
    "        \tnp.ndarray: wektor przewidzianych klas o długości n, gdzie n to liczba przykładów\n",
    "    \t\"\"\"\n",
    "\t\ty_pred = np.zeros(data.shape[0], dtype=int)  # Tworzymy tablicę na wyniki\n",
    "\t\t\n",
    "\t\tfor i, row in enumerate(data):  # Iterujemy przez każdy wiersz (przykład)\n",
    "\t\t\tnode = self  # Zaczynamy od korzenia drzewa\n",
    "\t\t\twhile node.answer is None:  # Dopóki nie dotrzemy do liścia\n",
    "\t\t\t\tif row[node.feature] < node.threshold:  # Sprawdzamy warunek podziału\n",
    "\t\t\t\t\tnode = node.left\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnode = node.right\n",
    "\t\t\ty_pred[i] = node.answer  # Przypisujemy klasę liścia do predykcji\n",
    "\t\treturn y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład trenowanie i testowania drzewa\n",
    "\n",
    "Później znajduje się przykład trenowania i testowania drzewa na zbiorze danych `iris`, który zawierający 150 próbek irysów, z czego każda próbka zawiera 4 atrybuty: długość i szerokość płatków oraz długość i szerokość działki kielicha. Każda próbka należy do jednej z trzech klas: `setosa`, `versicolor` lub `virginica`, które są zakodowane jak int.\n",
    "\n",
    "Możesz go wykorzystać do testowania swojej implementacji. Możesz też zaimplementować własne testy lub użyć innych zbiorów danych, np. innych [zbiorów danych z scikit-learn](https://scikit-learn.org/stable/datasets/toy_dataset.html#toy-datasets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=2024)\n",
    "\n",
    "tree_model = TreeNode()\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred = tree_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman Coding\n",
    "\n",
    "The goal of this task is to implement the Huffman Coding algorithm using a priority queue.  \n",
    "Let's import all the necessary libraries for this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Huffman Coding algorithm requires building the Huffman Tree. Let's create a class representing a single node in that tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char  # The character\n",
    "        self.freq = freq  # The frequency of the character\n",
    "        self.left = None   # Left child\n",
    "        self.right = None  # Right child\n",
    "\n",
    "    # Define comparison operators for heapq to sort nodes by frequency\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's create a function for building this tree. The general idea is to always place the two nodes with the lowest frequency at the bottom of the tree and merge them into one node with the summed-up frequency until there is only one node left, which becomes the root.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huffman_code(frequencies):\n",
    "    # Create a priority queue (min-heap) with Node objects\n",
    "    priority_queue = [Node(char, freq) for char, freq in frequencies.items()]\n",
    "    heapq.heapify(priority_queue)\n",
    "    \n",
    "    # Build the Huffman tree\n",
    "    while len(priority_queue) > 1:\n",
    "        left = heapq.heappop(priority_queue)\n",
    "        right = heapq.heappop(priority_queue)\n",
    "        \n",
    "        merged = Node(None, left.freq + right.freq)\n",
    "        merged.left = left\n",
    "        merged.right = right\n",
    "        \n",
    "        heapq.heappush(priority_queue, merged)\n",
    "    \n",
    "    # Generate the codes from the Huffman tree\n",
    "    root = priority_queue[0]\n",
    "    huffman_codes = {}\n",
    "    \n",
    "    def generate_codes(node, current_code):\n",
    "        if node:\n",
    "            # Generate code only if this is a real character and not a merged node\n",
    "            if node.char is not None:\n",
    "                huffman_codes[node.char] = current_code\n",
    "            generate_codes(node.left, current_code + \"0\")\n",
    "            generate_codes(node.right, current_code + \"1\")\n",
    "    \n",
    "    generate_codes(root, \"\")\n",
    "    return huffman_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's create a function for encoding a given message. For better visualization, I will treat zeros and ones as characters (rather than individual bits). Only later, when calculating the bit size gain from the compression, will I ensure that both the compressed and original texts match their actual sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, huffman_codes):\n",
    "    return ''.join(huffman_codes[char] for char in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function for decoding the encoded text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoded_text, huffman_codes):\n",
    "    # Reverse the code dictionary to decode\n",
    "    reverse_codes = {v: k for k, v in huffman_codes.items()}\n",
    "    \n",
    "    decoded_text = []\n",
    "    current_code = \"\"\n",
    "    \n",
    "    for bit in encoded_text:\n",
    "        current_code += bit\n",
    "        if current_code in reverse_codes:\n",
    "            decoded_text.append(reverse_codes[current_code])\n",
    "            current_code = \"\"\n",
    "    \n",
    "    return ''.join(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's calculate the actual bit size of a message. For the compressed message, it is just the number of 0s and 1s, but for the original message, we need to multiply the length of the message by the fixed-length size of character encoding. Let's assume that our messages will always consist of 26 Latin characters, 10 digits, and 1 space. The closest larger multiple of 2 is 64, which is 2^6, so the fixed-length encoding will be 6 bits long. (It would be 8 bits if we accept all ASCII characters.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compressed_size(encoded_text):\n",
    "    return len(encoded_text)\n",
    "\n",
    "def calculate_fixed_size(text, num_bits=6):\n",
    "    return len(text) * num_bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need a function to display the results of Huffman encoding. The following `display()` function takes in only one parameter, which is the path to the .txt file that contains the text for encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fixed_length_bits(num_unique_chars):\n",
    "    return math.ceil(math.log2(num_unique_chars))\n",
    "\n",
    "def display(file_path):\n",
    "    # Read the text from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    frequencies = collections.Counter(text)\n",
    "    huffman_codes = create_huffman_code(frequencies)\n",
    "\n",
    "    print(\"Huffman Codes:\")\n",
    "    for char, code in huffman_codes.items():\n",
    "        print(f\"'{char}': {code}\")\n",
    "\n",
    "    encoded_text = encode(text, huffman_codes)\n",
    "    decoded_text = decode(encoded_text, huffman_codes)\n",
    "    compressed_size = calculate_compressed_size(encoded_text)\n",
    "    num_unique_chars = len(frequencies)\n",
    "\n",
    "    # Calculate the bits needed for fixed-length encoding based on unique character count\n",
    "    fixed_length_bits = calculate_fixed_length_bits(num_unique_chars)\n",
    "    fixed_size = calculate_fixed_size(text, num_bits=fixed_length_bits)\n",
    "\n",
    "    print(f\"Compressed Size: {compressed_size} bits\")\n",
    "    print(f\"Fixed-Length Encoding Size: {fixed_size} bits\")\n",
    "\n",
    "    # Calculate the ratio between the compressed size and the fixed-size encoding\n",
    "    if fixed_size != 0:\n",
    "        compression_ratio = compressed_size / fixed_size\n",
    "    else:\n",
    "        compression_ratio = 0\n",
    "\n",
    "    print(f\"Compression Ratio (Compressed / Fixed-Length): {compression_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's see the results for the `norm_wiku_sample.txt` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huffman Codes:\n",
      "'e': 000\n",
      "'m': 00100\n",
      "'y': 001010\n",
      "'k': 0010110\n",
      "'4': 001011100\n",
      "'x': 001011101\n",
      "'5': 001011110\n",
      "'3': 001011111\n",
      "'s': 0011\n",
      "'w': 010000\n",
      "'b': 010001\n",
      "'c': 01001\n",
      "'r': 0101\n",
      "'o': 0110\n",
      "'n': 0111\n",
      "'i': 1000\n",
      "'d': 10010\n",
      "'2': 10011000\n",
      "'9': 10011001\n",
      "'v': 1001101\n",
      "'g': 100111\n",
      "'t': 1010\n",
      "'p': 101100\n",
      "'f': 101101\n",
      "'l': 10111\n",
      "'a': 1100\n",
      "'h': 11010\n",
      "'8': 110110000\n",
      "'j': 110110001\n",
      "'0': 11011001\n",
      "'q': 1101101000\n",
      "'z': 1101101001\n",
      "'6': 1101101010\n",
      "'7': 1101101011\n",
      "'1': 11011011\n",
      "'u': 110111\n",
      "' ': 111\n",
      "Compressed Size: 46489714 bits\n",
      "Fixed-Length Encoding Size: 64733646 bits\n",
      "Compression Ratio (Compressed / Fixed-Length): 0.72\n"
     ]
    }
   ],
   "source": [
    "display(\"norm_wiki_sample.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

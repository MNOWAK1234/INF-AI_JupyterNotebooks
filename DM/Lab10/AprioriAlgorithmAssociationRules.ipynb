{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori Algorithm Implementation Challenge\n",
    "\n",
    "**Objective:** Implement the Apriori algorithm for association rule mining from scratch.\n",
    "\n",
    "The Apriori algorithm works in three main phases:\n",
    "1. **Candidate Generation**: Create potential itemsets of increasing size\n",
    "2. **Support Counting**: Determine which itemsets meet minimum support\n",
    "3. **Rule Generation**: Create association rules from frequent itemsets\n",
    "\n",
    "### Apriori Principle\n",
    "*\"All subsets of a frequent itemset must also be frequent.\"*\n",
    "This is key for pruning the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "transactions = [\n",
    "    ['milk', 'bread', 'eggs'],\n",
    "    ['milk', 'bread'],\n",
    "    ['bread', 'eggs'],\n",
    "    ['milk', 'eggs'],\n",
    "    ['milk', 'bread', 'eggs', 'cheese'],\n",
    "    ['cheese', 'eggs'],\n",
    "    ['cheese'],\n",
    "    ['milk', 'cheese', 'eggs']\n",
    "]\n",
    "\n",
    "# Preprocessing function (given)\n",
    "def preprocess_transactions(transactions):\n",
    "    return [list(set(t)) for t in transactions]\n",
    "\n",
    "transactions = preprocess_transactions(transactions)\n",
    "unique_items = list(set(item for t in transactions for item in t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Implement Support Calculation\n",
    "\n",
    "Complete the function below to calculate support for an itemset. (You should already have this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test support for ['milk']: 0.625\n"
     ]
    }
   ],
   "source": [
    "def calculate_support(itemset, transactions):\n",
    "    \"\"\"\n",
    "    Calculate the support of an itemset.\n",
    "    \n",
    "    Parameters:\n",
    "    itemset (list): A list of items\n",
    "    transactions (list): List of all transactions\n",
    "    \n",
    "    Returns:\n",
    "    float: support count (between 0 and 1)\n",
    "    \"\"\"\n",
    "    counter=0\n",
    "    allPresent=True\n",
    "    for transaction in transactions:\n",
    "        for item in itemset:\n",
    "            if item not in transaction:\n",
    "                allPresent=False\n",
    "                break\n",
    "        if allPresent:\n",
    "            counter+=1\n",
    "        allPresent=True\n",
    "    return counter/len(transactions)\n",
    "\n",
    "# Test your function\n",
    "print(\"Test support for ['milk']:\", calculate_support(['milk'], transactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate Candidate Itemsets\n",
    "\n",
    "Implement the function to generate candidate itemsets of size k from frequent itemsets of size k-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test candidates: [['bread', 'milk'], ['eggs', 'milk'], ['bread', 'eggs']]\n"
     ]
    }
   ],
   "source": [
    "def generate_candidates(prev_freq_itemsets, k):\n",
    "    \"\"\"\n",
    "    Generate candidate itemsets of size k using frequent itemsets of size k-1.\n",
    "    \n",
    "    Parameters:\n",
    "    prev_freq_itemsets (list): Frequent itemsets of size k-1\n",
    "    k (int): The size of candidates to generate\n",
    "    \n",
    "    Returns:\n",
    "    list: Candidate itemsets of size k\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    n = len(prev_freq_itemsets)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # Merge two itemsets if their first k-2 items match\n",
    "            # This helps avoid redundancy (just add eahc candidate 1 time)\n",
    "            l1 = sorted(prev_freq_itemsets[i])\n",
    "            l2 = sorted(prev_freq_itemsets[j])\n",
    "            \n",
    "            if l1[:k-2] == l2[:k-2]:\n",
    "                candidate = sorted(list(set(l1) | set(l2)))\n",
    "                if candidate not in candidates:\n",
    "                    candidates.append(candidate)\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "# Test with k=2 (should print combinations of size 2)\n",
    "print(\"Test candidates:\", generate_candidates([['milk'], ['bread'], ['eggs']], 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Pruning\n",
    "\n",
    "Complete the pruning function using the Apriori principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test pruning: [['milk', 'bread']]\n"
     ]
    }
   ],
   "source": [
    "def prune_candidates(candidates, prev_freq_itemsets, k):\n",
    "    \"\"\"\n",
    "    Prune candidates whose subsets are not all frequent.\n",
    "    \n",
    "    Parameters:\n",
    "    candidates (list): Candidate itemsets\n",
    "    prev_freq_itemsets (list): Frequent itemsets of size k-1\n",
    "    k (int): Size of the candidates\n",
    "    \n",
    "    Returns:\n",
    "    list: Pruned candidate itemsets\n",
    "    \"\"\"\n",
    "    pruned = []\n",
    "    \n",
    "    # Convert to set of tuples for faster lookup\n",
    "    prev_freq_set = set(tuple(sorted(itemset)) for itemset in prev_freq_itemsets)\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        all_subsets_frequent = True\n",
    "        \n",
    "        # Generate all (k-1)-sized subsets\n",
    "        for subset in combinations(candidate, k-1):\n",
    "            if tuple(sorted(subset)) not in prev_freq_set:\n",
    "                all_subsets_frequent = False\n",
    "                break\n",
    "        \n",
    "        if all_subsets_frequent:\n",
    "            pruned.append(candidate)\n",
    "    \n",
    "    return pruned\n",
    "\n",
    "# Test pruning (should remove ['milk', 'cheese'] because 'cheese' is not in prev_freq_itemsets)\n",
    "print(\"Test pruning:\", prune_candidates([['milk', 'bread'], ['milk', 'cheese']], \n",
    "                                        [['milk'], ['bread'], ['eggs']], 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Complete the Apriori Algorithm\n",
    "\n",
    "Implement the main function that ties all steps together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori results: {1: [['eggs'], ['milk'], ['bread'], ['cheese']], 2: [['eggs', 'milk'], ['bread', 'eggs'], ['cheese', 'eggs'], ['bread', 'milk'], ['cheese', 'milk']], 3: [['bread', 'eggs', 'milk'], ['cheese', 'eggs', 'milk']]}\n"
     ]
    }
   ],
   "source": [
    "def apriori(transactions, min_support=0.2):\n",
    "    \"\"\"\n",
    "    The complete Apriori algorithm implementation.\n",
    "    \n",
    "    Parameters:\n",
    "    transactions (list): List of transactions\n",
    "    min_support (float): Minimum support threshold\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with keys as itemset sizes and values as frequent itemsets\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate initial 1-item frequent itemsets\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_counts[item] += 1\n",
    "    \n",
    "    num_transactions = len(transactions)\n",
    "    freq_itemsets = []\n",
    "    \n",
    "    for item, count in item_counts.items():\n",
    "        support = count / num_transactions\n",
    "        if support >= min_support:\n",
    "            freq_itemsets.append([item])\n",
    "\n",
    "    result = {1: freq_itemsets}\n",
    "    k = 2  # Size of itemsets to generate next\n",
    "\n",
    "    while True:\n",
    "        candidates = generate_candidates(result[k - 1], k)\n",
    "        candidates = prune_candidates(candidates, result[k - 1], k)\n",
    "        # Count support and collect frequent itemsets\n",
    "        valid_itemsets = []\n",
    "        for candidate in candidates:\n",
    "            support = calculate_support(candidate, transactions)\n",
    "            if support >= min_support:\n",
    "                valid_itemsets.append(candidate)\n",
    "        \n",
    "        if not valid_itemsets:\n",
    "            break\n",
    "        \n",
    "        result[k] = valid_itemsets\n",
    "        k += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "# Test the full algorithm\n",
    "print(\"Apriori results:\", apriori(transactions, 0.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Association Rule Generation\n",
    "\n",
    "Implement rule generation from frequent itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rules: [{'antecedent': ['milk'], 'consequent': ['bread'], 'support': 0.375, 'confidence': 0.6}, {'antecedent': ['bread'], 'consequent': ['milk'], 'support': 0.375, 'confidence': 0.75}, {'antecedent': ['bread'], 'consequent': ['eggs'], 'support': 0.375, 'confidence': 0.75}, {'antecedent': ['eggs'], 'consequent': ['bread'], 'support': 0.375, 'confidence': 0.5}]\n"
     ]
    }
   ],
   "source": [
    "def generate_rules(freq_itemsets, transactions, min_confidence=0.5):\n",
    "    \"\"\"\n",
    "    Generate association rules from frequent itemsets.\n",
    "    \n",
    "    Parameters:\n",
    "    freq_itemsets (dict): Frequent itemsets from apriori\n",
    "    transactions (list): List of all transactions\n",
    "    min_confidence (float): Minimum confidence threshold\n",
    "    \n",
    "    Returns:\n",
    "    list: Association rules as dicts with keys 'antecedent', 'consequent', 'support', 'confidence'\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "\n",
    "    for k, itemsets in freq_itemsets.items():\n",
    "        if k < 2:\n",
    "            continue\n",
    "        \n",
    "        for itemset in itemsets:\n",
    "            itemset_support = calculate_support(itemset, transactions)\n",
    "            \n",
    "            # Generate all non-empty proper subsets (antecedents)\n",
    "            for i in range(1, len(itemset)):\n",
    "                for antecedent in combinations(itemset, i):\n",
    "                    antecedent = list(antecedent)\n",
    "                    consequent = [item for item in itemset if item not in antecedent]\n",
    "                    \n",
    "                    antecedent_support = calculate_support(antecedent, transactions)\n",
    "                    confidence = itemset_support / antecedent_support if antecedent_support > 0 else 0\n",
    "                    \n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append({\n",
    "                            'antecedent': antecedent,\n",
    "                            'consequent': consequent,\n",
    "                            'support': itemset_support,\n",
    "                            'confidence': confidence\n",
    "                        })\n",
    "    \n",
    "    return rules\n",
    "\n",
    "# Example test with your existing transactions and freq_itemsets:\n",
    "freq_itemsets = {\n",
    "    1: [['milk'], ['bread'], ['eggs']], \n",
    "    2: [['milk', 'bread'], ['bread', 'eggs']]\n",
    "}\n",
    "print(\"Test rules:\", generate_rules(freq_itemsets, transactions, 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Testing\n",
    "\n",
    "Run your complete implementation on the sample dataset and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "Size 1: [['eggs'], ['milk'], ['bread'], ['cheese']]\n",
      "Size 2: [['eggs', 'milk'], ['bread', 'eggs'], ['cheese', 'eggs'], ['bread', 'milk'], ['cheese', 'milk']]\n",
      "Size 3: [['bread', 'eggs', 'milk'], ['cheese', 'eggs', 'milk']]\n",
      "\n",
      "Association Rules:\n",
      "['eggs'] => ['milk'] (supp: 0.50, conf: 0.67)\n",
      "['milk'] => ['eggs'] (supp: 0.50, conf: 0.80)\n",
      "['bread'] => ['eggs'] (supp: 0.38, conf: 0.75)\n",
      "['eggs'] => ['bread'] (supp: 0.38, conf: 0.50)\n",
      "['cheese'] => ['eggs'] (supp: 0.38, conf: 0.75)\n",
      "['eggs'] => ['cheese'] (supp: 0.38, conf: 0.50)\n",
      "['bread'] => ['milk'] (supp: 0.38, conf: 0.75)\n",
      "['milk'] => ['bread'] (supp: 0.38, conf: 0.60)\n",
      "['cheese'] => ['milk'] (supp: 0.25, conf: 0.50)\n",
      "['bread'] => ['eggs', 'milk'] (supp: 0.25, conf: 0.50)\n",
      "['bread', 'eggs'] => ['milk'] (supp: 0.25, conf: 0.67)\n",
      "['bread', 'milk'] => ['eggs'] (supp: 0.25, conf: 0.67)\n",
      "['eggs', 'milk'] => ['bread'] (supp: 0.25, conf: 0.50)\n",
      "['cheese'] => ['eggs', 'milk'] (supp: 0.25, conf: 0.50)\n",
      "['cheese', 'eggs'] => ['milk'] (supp: 0.25, conf: 0.67)\n",
      "['cheese', 'milk'] => ['eggs'] (supp: 0.25, conf: 1.00)\n",
      "['eggs', 'milk'] => ['cheese'] (supp: 0.25, conf: 0.50)\n"
     ]
    }
   ],
   "source": [
    "# Test the complete workflow\n",
    "freq_itemsets = apriori(transactions, 0.2)\n",
    "rules = generate_rules(freq_itemsets, transactions, 0.5)\n",
    "\n",
    "# Display results\n",
    "print(\"Frequent Itemsets:\")\n",
    "for size, itemsets in freq_itemsets.items():\n",
    "    print(f\"Size {size}: {itemsets}\")\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for rule in rules:\n",
    "    print(f\"{rule['antecedent']} => {rule['consequent']} \"\n",
    "          f\"(supp: {rule['support']:.2f}, conf: {rule['confidence']:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
